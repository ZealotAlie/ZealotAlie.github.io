---
title: "[RealSense] 2-ReaSense SDK的接入与封装"
tags: RealSense
      游戏
---

为了方便在Cocos2dx中使用，我封装了RealSense SDK的手部追踪的部分。源码可以在这里[下载](https://pan.baidu.com/s/1boJlTt9)（密码：6q3p）。<!--more-->

最初之所以用Cocos2dx是因为当时在GitHub上已经有人封装了RealSense SDK到引擎中。但是后来测试发现并不能用。所以就直接自己简单封装了一个。

## SDK的开发环境配置
实感摄像头需要在Win8.1及以上系统上使用，使用前需要安装配套的驱动程序，此外开发者还需要安装配套的实感SDK开发套件，它包含了开发所需要使用的头文件库文件，此外还包含了几个简单的例子，方便开发者学习使用。这些组件的安装包都可以从英特尔官方网站免费下载，直接安装即可。

要在Cocos2d-x项目中使用实感的SDK十分的简单。只需要把实感SDK的相关头文件与所使用到的库文件包括进去就可以了。本课题中用到的两个lib都位于SDK的安装目录下，需要在项目中配置头文件目录，附加库目录以及库名，具体配置可以参考SDK附带的示例。

## 系统总体架构
![系统总体架构图](/assets/images/2017-02-25-RealSense2/1.jpg)
*<br>系统总体架构图*
游戏的基本构架如上，第一部分是实感摄像头的控制中心，主要是调用了实感SDK中的相关函数，启动摄像头并从摄像头中获取数据。此外它还包括了对数据的分析以及相关的手势识别，重点说这一部分。

第二部分是事件监听组件，在游戏中一般不直接和摄像控制中心打交道，而是通过事件监听组件来获取摄像头的事件，例如手的移动事件，手势事件等，这部分的主要功能是方便开发者在游戏中处理输入事件，是摄像头控制中心与游戏之间沟通的桥梁。实际上这部分是cocos2dx引擎与封装的SDK的中间部分。

第三部分是游戏的逻辑部分，通过事件监听组件获取设备输入，然后驱动游戏中的角色的行为，同时还包括了界面UI的交互，游戏流程的控制等。不详述。

## 实感摄像头控制中心的设计和实现
摄像头由RealSenseCam类控制。RealSenseCam是一个单例类，在整个游戏进程中，它只被初始化一次，在游戏结束时再被释放。

它的主要工作流程如下：
![工作流程](/assets/images/2017-02-25-RealSense2/2.jpg)

## 初始化

除了一些参数的初始化外，还需要使用实感提供的函数来初始化摄像头。前面已经大致描述过了实感SDK的构架与类层次，所以首先要创建一个PXCSession，然后在创建好的PXCSession中创建PXCSenseManager，再开启手部追踪即可。代码如下：

```c++
void RealSenseCam::initCam(){
	m_iInitProgress = 0;
	m_bInitFailed = false;
	Definitions::appName = "RealsenseTest";
	initInfomation = "Creating Session";
	m_session = PXCSession::CreateInstance();
	if (!m_session)
	{
		initInfomation = "Failed Creating PXCSession\n";
		m_bInitFailed = true;
		return;
	}
	m_iInitProgress++;//1
	m_senseManager = m_session->CreateSenseManager();
	initInfomation = "Creating SenseManager";
	if (!m_senseManager)
	{
		initInfomation = "Failed Creating PXCSenseManager\n";
		m_bInitFailed = true;
		return;
	}
	m_iInitProgress++;//2
	initInfomation = "Enabling Hand Module";
	if (m_senseManager->EnableHand(0) != PXC_STATUS_NO_ERROR)
	{
		initInfomation = "Failed Enabling Hand Module\n";
		m_bInitFailed = true;
		return;
	}
	m_iInitProgress++;//3
	initInfomation = "Creating HandModule";
	m_handModule = m_senseManager->QueryHand();
	if (!m_handModule)
	{
		initInfomation = "Failed Creating PXCHandModule\n";
		m_bInitFailed = true;
		return;
	}
	m_iInitProgress++;//4
	m_handDataOutput = m_handModule->CreateOutput();
	initInfomation = "Creating HandData";
	if (!m_handDataOutput)
	{
		initInfomation = "Failed Creating PXCHandData\n";
		m_bInitFailed = true;
		return;
	}
	m_iInitProgress++;//5
	m_handConfiguration = m_handModule->CreateActiveConfiguration();
	initInfomation = "Creating HandConfiguration";
	if (!m_handConfiguration)
	{
		releaseAll();
		initInfomation = "Failed Creating PXCHandConfiguration\n";
		m_bInitFailed = true;
		return;
	}
	m_handConfiguration->SetTrackingMode(PXCHandData::TrackingModeType::TRACKING_MODE_FULL_HAND);

	/*log("-Gestures Are Enabled-\n");
	m_handConfiguration->EnableGesture(L"fist");*/
	// Apply configuration setup
	m_handConfiguration->ApplyChanges();
	log("-Skeleton Information Enabled-\n");

	initInfomation = "Gestures and Skeleton Are Enabled";
	if (m_senseManager->Init() == PXC_STATUS_NO_ERROR)
	{
		initInfomation = "SenseManager Initializing";
	}
	else
	{
		initInfomation = "Failed Initializing PXCSenseManager\n";
		m_bInitFailed = true;
		return;
	}
	m_iInitProgress++;//6
	Director::getInstance()->getScheduler()->schedule(schedule_selector(RealSenseCam::update), RealSenseCam::getInstance(), 0, false);
	std::thread m_ioTask(&RealSenseCam::task, this);//创建一个分支线程，回调到myThread函数里
	m_ioTask.detach();
}
```

没有太多需要理解的地方，实际上只是按照SDK要求的流程来启动摄像头设置参数，但是最好还是注意错误信息。

```c++
Director::getInstance()->getScheduler()->schedule(schedule_selector(RealSenseCam::update), RealSenseCam::getInstance(), 0, false);
	std::thread m_ioTask(&RealSenseCam::task, this);//创建一个分支线程，回调到myThread函数里
```

首先我们像Cocos2dx注册了一个定时器，每帧执行一次Update。此外我们新建了一个线程用于从SDK中获取数据。

在子线程中，用PXCSenseManager的AcquireFrame()函数来获取数据帧。获取数据帧的过程是阻塞的，线程需要等待SDK传来的数据，因此使用一个新线程来执行对数据帧的获取。C++11的标准库中为程序员提供了一个十分方便的多线程操作类std::thread，在代码中，使用它来创建一个线程，用于执行获取数据帧的操作。

这个线程的主要工作就是让实感摄像头尽可能的为应用提供数据，然后再把数据提交到游戏线程。这些工作都由RealSenseCam::task()完成。在task()里，循环的从摄像头处获取数据，然后把这些数据保存起来。同时还要对获取的数据进行处理，完成手势识别的工作。

## 手部数据处理
对于每一只手，实感SDK都能够为开发者提供22个数据点，每只手指上有四个数据点，掌心和手掌根部各有一个数据点。

![hand](/assets/images/2017-02-25-RealSense2/3.jpg)

虽然实感SDK支持同时识别两只手，但在识别两只手时，速度和准确度都会有所下降，所以RealSenseCam仅支持单手操作。对SDK为开发者提供的22个关节数据，在程序中使用结构体JointsData来存储这些数据。这些关节数据是以空间坐标的形式表示的，空间的坐标系如图所示，以摄像头所在位置为空间坐标的原点。

```c++
//实际上SDK有用于存储的数据结构但为了方便使用我还是新建了结构体。当然直接使用SDK提供的数据结构也完全没问题。
enum JointType
{
  /// The center of the wrist
  JOINT_WRIST = 0
  , JOINT_CENTER            /// The center of the palm
  , JOINT_THUMB_BASE        /// Thumb finger joint 1 (base)
  , JOINT_THUMB_JT1         /// Thumb finger joint 2
  , JOINT_THUMB_JT2         /// Thumb finger joint 3
  , JOINT_THUMB_TIP         /// Thumb finger joint 4 (fingertip)
  , JOINT_INDEX_BASE        /// Index finger joint 1 (base)
  , JOINT_INDEX_JT1         /// Index finger joint 2
  , JOINT_INDEX_JT2         /// Index finger joint 3
  , JOINT_INDEX_TIP         /// Index finger joint 4 (fingertip)
  , JOINT_MIDDLE_BASE       /// Middle finger joint 1 (base)
  , JOINT_MIDDLE_JT1        /// Middle finger joint 2
  , JOINT_MIDDLE_JT2        /// Middle finger joint 3
  , JOINT_MIDDLE_TIP        /// Middle finger joint 4 (fingertip)
  , JOINT_RING_BASE         /// Ring finger joint 1 (base)
  , JOINT_RING_JT1          /// Ring finger joint 2
  , JOINT_RING_JT2          /// Ring finger joint 3
  , JOINT_RING_TIP          /// Ring finger joint 4 (fingertip)
  , JOINT_PINKY_BASE        /// Pinky finger joint 1 (base)
  , JOINT_PINKY_JT1         /// Pinky finger joint 2
  , JOINT_PINKY_JT2         /// Pinky finger joint 3
  , JOINT_PINKY_TIP         /// Pinky finger joint 4 (fingertip)        
};
enum HandSide{
  LEFT_HAND,
  RIGHT_HAND,
  UNKNOW_HAND,
};
struct JointsData
{
  HandSide handInfo;
  Vec3 jointPoistion[JOINT_PINKY_TIP + 1];
  Vec3 jointSpeed[JOINT_PINKY_TIP + 1];
}
```

除了位置外，JointsData中还保持了22个关节点的速度信息。由于SDK本身无法计算速度，所以我把当前数据帧关节的位置相对于前一数据帧关节的位置的差值作为速度信息保持起来，这些速度信息可以用于了解手的运动方向。

![cord](/assets/images/2017-02-25-RealSense2/4.jpg)

前面提到实现的RealSenseCam类只支持单手操作，所以需要对摄像头传来的手的数据稍作处理。本课题中的处理方式是，以第一个识别到的手作为追踪的对象，RealSenseCam会持续记录这个手的信息，直到它脱离了摄像头的追踪。当前一只手脱离摄像头追踪时，如果还有另一只手正在被追踪，则RealSenseCam会开始记录这只手的信息。

实感的SDK虽然为开发者提供了识别当前手是左手还是右手的功能，但同样因为识别精度的问题，在本课题中不使用这项功能。可以通过调用SDK提供的函数，来获取追踪的手的数量，当手的数量为1时不需要做任何处理；当手的数量为2时，通过对比两只手的22个关节与前一帧保存的数据的相对距离，距离小的一只手将被认为是前一帧的同一只手，并保存这只手的信息；当手的数量为0时，会触发一个控制丢失事件，在游戏中这个事件被用于暂停游戏。需要注意的是，在程序正常进行的过程中也可能出现某一数据帧丢失追踪信息的情况，所以当识别到的手数量为0时，不是马上就触发事件，而是使用计数器进行计数，连续丢失数据帧超过三次才会触发控制丢失事件。

```c++
PXCHandData::JointData jointData;
PXCHandData::IHand *hand;
bool isLeftHand = false;
int num = m_handDataOutput->QueryNumberOfHands();
if (num == 0){
  m_iLostCounter++;
  if (m_iLostCounter > 3){
    m_isControlLost = true;
  }
}
else if (num == 1){
  m_isControlLost = false;
  m_iLostCounter = 0;
  m_handDataOutput->QueryHandData(PXCHandData::ACCESS_ORDER_BY_TIME, 0, hand);
  for (int j = 0; j <= JOINT_PINKY_TIP; ++j)
  {
    if (hand->QueryTrackedJoint((PXCHandData::JointType)j, jointData) == PXC_STATUS_NO_ERROR)
    {
      m_jointData.jointSpeed[j].x = jointData.positionWorld.x - m_jointData.jointPoistion[j].x;
      m_jointData.jointSpeed[j].y = jointData.positionWorld.y - m_jointData.jointPoistion[j].y;
      m_jointData.jointSpeed[j].z = jointData.positionWorld.z - m_jointData.jointPoistion[j].z;

      m_jointData.jointPoistion[j].x = jointData.positionWorld.x;
      m_jointData.jointPoistion[j].y = jointData.positionWorld.y;
      m_jointData.jointPoistion[j].z = jointData.positionWorld.z;
    }
  }
}
else{
  m_isControlLost = false;
  m_iLostCounter = 0;
  for (int i = 0; i < num; ++i)
  {
    m_handDataOutput->QueryHandData(PXCHandData::ACCESS_ORDER_BY_TIME, i, hand);
    /*std::string handSide = "Unknown Hand";
    if (hand->QueryBodySide() == PXCHandData::BODY_SIDE_LEFT) {
    handSide = "Left Hand";
    isLeftHand = true;
    }
    else{
    handSide = "Right Hand";
    isLeftHand = false;
    }*/
    for (int j = 0; j <= JOINT_PINKY_TIP; ++j)
    {
      if (hand->QueryTrackedJoint((PXCHandData::JointType)j, jointData) == PXC_STATUS_NO_ERROR)
      {
        m_tempData[i].jointPoistion[j].x = jointData.positionWorld.x;
        m_tempData[i].jointPoistion[j].y = jointData.positionWorld.y;
        m_tempData[i].jointPoistion[j].z = jointData.positionWorld.z;
      }
    }
    m_jointData = m_jointData.getDifferent(m_tempData[0]) < m_jointData.getDifferent(m_tempData[1]) ? m_tempData[0] : m_tempData[1];
  }
}
```

## 手势的识别
之所以直接用SDK提供的手势，是因为识别精度不足。

因为SDK提供了太过丰富的手势的识别，而很多手势之间本身差异就比较小，SDK必须兼顾这些差异（ps：以上只是我的臆想，我并不知道为什么它那么难用。），所以我觉得还是专门为自己的游戏设计需要的手势才是合理的解决办法。

在我的游戏中，共使用了以下三种容易识别区分的手势：

### 握拳
握拳动作在游戏中被用于武器的选择和蓄力攻击操作。判断握拳手势主要通过判断玩家的四个手指的指尖的位置来确定，正常情况下，手掌在张开时，掌心到指尖的距离，一定会大于掌心到手指根部的距离，求出两者的比值即可得到手指弯曲的程度，在程序中使用bendRate表示。通过判断四只手指的bendRate的大小就可以判断手掌是否是握拳的状态。当bendRate小于预设的阈值（在程序中为1.0）时，判断为握拳动作开始，将会触发握拳开始事件；当bendRate值大于阈值（在程序中为1.2）时，判断握拳动作结束，将会触发握拳结束事件。

```c++
void RealSenseCam::fistTask(){
	testValue = 0;
	for (int i = JOINT_INDEX_TIP; i < 22; i += 4){
		testValue += ((m_jointData.jointPoistion[i] - m_jointData.jointPoistion[JOINT_CENTER]).length()) /
			((m_jointData.jointPoistion[i-3] - m_jointData.jointPoistion[JOINT_CENTER]).length());
	}
	testValue /= 4;
	if (m_bIsBended){
		if (testValue > m_fbendValueUp){
			m_bIsBended = false;
			m_bIsFistEnded = true;
		}
	}
	else{
		if (testValue < m_fbendValueDown){
			m_bIsBended = true;
			m_bIsFistBegan = true;
		}
	}
}
```

### 手掌滑动
手掌滑动的动作在游戏中主要被用于场景切换。识别这一手势主要是通过判断手掌移动的速度和方向来实现的。

前面提到，在程序中把两个数据帧内点的相对位移认为是速度，所以程序先求出22个关节的平均速度，同样忽略距离因素，得到平面上的速度向量avSpeed2d，并计算出y方向上的速度与x方向上的速度的比值的绝对值tanAbs与速度的大小speed2d。

通过判断tanAbs的大小，可以判断此时手的运动方向十分为水平，在程序中，判断阈值被定义为0.577，即tan30°，tanAbs小于阈值时视为手掌是在水平运动。

同时还需要判断手掌移动的速度大小，当速度大于阈值且方向正确时，程序认为手掌的滑动动作开始，记录此时手掌的运动方向是向左还是向右，并在接下来数帧的时间内，记录手掌的移动状态。

手掌移动速度大小的阈值共有两个，分别为shiftInSpeed和shiftOutSpeed，在程序中分别取0.018和0.015，shiftInSpeed即是前面用于判断动作是否开始的阈值。一旦动作开始，程序会开始比较接下来几个数据帧内手掌移动的速度和方向，方向的判断同上，但还要判断是向左还是向右并与动作开始时的速度方向比较，速度判断的阈值则变为shiftOutSpeed，速度方向不对或者速度太小都会被判断为不合格，并用一个整数记录下不合格的次数；如果判断合格，则会将此次速度累加到actionSpeed向量中。一旦不合格次数过多，则认为动作结束，然后判断actionSpeed在x方向上的累计位移，如果大于阈值则认为是动作正确完成，触发对应事件，否则动作结束不触发对应事件，并重置相关量。

```c++
void RealSenseCam::shiftTask(){
	if (m_shiftAction.actionEnded){
		return;
	}
	Vec3 avSpeed;
	for (int i = 0; i <= JOINT_PINKY_TIP; ++i){
		avSpeed += m_jointData.jointSpeed[i];
	}
	avSpeed.x/= (float)JOINT_PINKY_TIP + 1;
	avSpeed.y /= (float)JOINT_PINKY_TIP + 1;
	Vec2 avSpeed2d(avSpeed.x, avSpeed.y);
	float tanAbs = fabsf(avSpeed2d.y / avSpeed2d.x);
	float speed2d = avSpeed2d.length();
	if (m_shiftAction.actionStarted){
		float speedTanAbs = fabsf(m_shiftAction.actionSpeed.y / m_shiftAction.actionSpeed.x);
		if (m_shiftAction.shiftDirection*avSpeed2d.x>0&&//same dir
			speed2d > m_camConfig.shiftOutSpeed&&//high speed
			tanAbs < m_camConfig.shiftTan){//direction 
			m_shiftAction.actionSpeed += avSpeed2d;
		}
		else{
			m_shiftAction.missCounter++;
			if (m_shiftAction.missCounter > m_camConfig.shiftEndNum){
				if (m_shiftAction.actionSpeed.x*m_shiftAction.shiftDirection>m_camConfig.shiftNeedDis&&
					speedTanAbs< m_camConfig.shiftTan){
					m_shiftAction.actionEnded = true;
					m_shiftAction.actionStarted = false;
				}
				else{
					m_shiftAction.reset();
				}
			}
		}
	}
	else{
		if (speed2d > m_camConfig.shiftInSpeed&&tanAbs < m_camConfig.shiftTan){
			m_shiftAction.shiftDirection = avSpeed2d.x > 0 ? 1 : -1;
			m_shiftAction.actionStarted = true;
		}
	}

}
```

### 拇指弯向掌心
这个动作在游戏中被用于切换武器。判断这个动作主要是通过判断两个向量夹角来实现的。basetoCenter是掌心指向拇指和手掌连接处的关节的向量，tipToCenter是掌心到拇指指尖的向量，忽略距离因素，得到它们在2d平面上的向量basetoCenter2d和tipToCenter2d，求两向量夹角的余弦值，当手掌正常张开时，两向量的夹角较小，当拇指向掌心弯曲时，向量夹角增大，余弦值变大，所以只需要确定合适的阈值，就可以判断拇指是否弯向掌心。从手掌自然张开到拇指弯曲到掌心再到手掌自然张开视为一次动作，触发一次相应的事件。

```c++
void RealSenseCam::thumbTask(){
	//baseto
	auto basetoCenter = m_jointData.jointPoistion[JOINT_THUMB_BASE] - m_jointData.jointPoistion[JOINT_CENTER];
	auto tipToCenter = m_jointData.jointPoistion[JOINT_THUMB_TIP] - m_jointData.jointPoistion[JOINT_CENTER];
	Vec2 basetoCenter2d(basetoCenter.x, basetoCenter.y);
	Vec2 tipToCenter2d(tipToCenter.x, tipToCenter.y);
	float disSq = basetoCenter2d.lengthSquared() - basetoCenter2d.lengthSquared();
	float cross = basetoCenter2d.cross(tipToCenter2d);
	float dot = basetoCenter2d.dot(tipToCenter2d);
	float cos = dot / basetoCenter2d.length() / tipToCenter2d.length();
	if (!m_thumbAction.actionStarted){
		//if (disSq>0.0001f&&disSq<0.0028f){

		if (cos<m_camConfig.thumbInCos){
			m_thumbAction.actionStarted = true;
		}
	}
	else{
		if (cos> m_camConfig.thumbOutCos){
			if (m_thumbAction.elapsedTime > m_camConfig.thumbEffectTime)
			{
				m_thumbAction.actionEnded = true;
			}
			else if (m_thumbAction.elapsedTime < m_camConfig.thumbIgnoreTime){
				m_thumbAction.actionStarted = false;
				m_thumbAction.elapsedTime = 0.f;
			}
		}
	}
}
```

## 数据抖动与消抖
因为数据量本身过小，在实际使用中，每秒大概能提供30到40组数据，而游戏的帧数一般保持在60左右。所以我只是简单的将多组数据叠加求和平均来让抖动不那么明显。

## 小结
实际上并没有太多东西。我的观点是，简单的东西往往是有效的，所以不要想得太复杂。这部分的内容实际上相对于游戏引擎和语言都是较为独立的，所以也可以用在别的引擎和别的语言中。

当然许多参数的调整完全是依靠个人的感觉来做的，所以建议还是自己调节好参数来适应自己的应用。
